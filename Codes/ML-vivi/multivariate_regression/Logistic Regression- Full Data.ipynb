{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (in this case it is CSV)\n",
    "\n",
    "df1 =pd.read_csv( \"../../CSVTables/Cross_Tb1.csv\")\n",
    "df2 =pd.read_csv(\"../../CSVTables/Cross_Tb2.csv\")\n",
    "df3 = pd.read_csv(\"../../CSVTables/Cross_Tb3.csv\")\n",
    "df4 = pd.read_csv(\"../../CSVTables/Cross_Tb4.csv\")\n",
    "df5 = pd.read_csv(\"../../CSVTables/Cross_Tb5.csv\")\n",
    "# df6 = pd.read_csv(\"../../CSVTables/Cross_Tb6.csv\")\n",
    "df7 = pd.read_csv(\"../../CSVTables/Cross_Tb7.csv\")\n",
    "# df8 = pd.read_csv(\"../../CSVTables/Cross_Tb8.csv\")\n",
    "# df9 = pd.read_csv(\"../../CSVTables/Cross_Tb9.csv\")\n",
    "df10 = pd.read_csv(\"../../CSVTables/Cross_Tb10.csv\")\n",
    "df11 = pd.read_csv(\"../../CSVTables/Cross_Tb11.csv\")\n",
    "df12 = pd.read_csv(\"../../CSVTables/Cross_Tb12.csv\")\n",
    "df13 = pd.read_csv(\"../../CSVTables/Cross_Tb13.csv\")\n",
    "# df14 = pd.read_csv(\"../../CSVTables/Cross_Tb14.csv\")\n",
    "df15 = pd.read_csv(\"../../CSVTables/Cross_Tb15.csv\")\n",
    "# df16 = pd.read_csv(\"../../CSVTables/Cross_Tb16.csv\")\n",
    "df17 = pd.read_csv(\"../../CSVTables/Cross_Tb17.csv\")\n",
    "# df18 = pd.read_csv(\"../../CSVTables/Cross_Tb18.csv\")\n",
    "# df19 = pd.read_csv(\"../../CSVTables/Cross_Tb19.csv\")\n",
    "df20 = pd.read_csv(\"../../CSVTables/Cross_Tb20.csv\")\n",
    "df21 = pd.read_csv(\"../../CSVTables/Cross_Tb21.csv\")\n",
    "df22 = pd.read_csv(\"../../CSVTables/Cross_Tb22.csv\")\n",
    "df23 = pd.read_csv(\"../../CSVTables/Cross_Tb23.csv\")\n",
    "# df24 = pd.read_csv(\"../../CSVTables/Cross_Tb24.csv\")\n",
    "df25 = pd.read_csv(\"../../CSVTables/Cross_Tb25.csv\")\n",
    "# df26 = pd.read_csv(\"../../CSVTables/Cross_Tb26.csv\")\n",
    "df27 = pd.read_csv(\"../../CSVTables/Cross_Tb27.csv\")\n",
    "df28 = pd.read_csv(\"../../CSVTables/Cross_Tb28.csv\")\n",
    "df29 = pd.read_csv(\"../../CSVTables/Cross_Tb29.csv\")\n",
    "df30 = pd.read_csv(\"../../CSVTables/Cross_Tb30.csv\")\n",
    "df31 = pd.read_csv(\"../../CSVTables/Cross_Tb31.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Using CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create list of dataframe so it is easier to iterate\n",
    "\n",
    "list_of_df = [df1, df2, df3, df4, df5, df7, df10, df11, df12, df13, df15, df17, df20, df21, df22, df23, df25, df27, df28, df29, df30, df31]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#training code\n",
    "list_of_df[2] = list_of_df[2].drop( list_of_df[2].columns[[0,1]], axis=1 )\n",
    "\n",
    "list_of_df[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the data I don't want.\n",
    "#Erase this step when finally using dataframe \n",
    "\n",
    "\n",
    "for dframe in range(0, len(list_of_df)-1 ):\n",
    "    list_of_df[dframe] = list_of_df[dframe].drop( list_of_df[dframe].columns[[0,1]], axis=1 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['Other'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-591df9e46661>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlist_of_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdframe\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   7207\u001b[0m         \"\"\"\n\u001b[0;32m   7208\u001b[0m         return self._join_compat(\n\u001b[1;32m-> 7209\u001b[1;33m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7210\u001b[0m         )\n\u001b[0;32m   7211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   7230\u001b[0m                 \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7231\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7232\u001b[1;33m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7233\u001b[0m             )\n\u001b[0;32m   7234\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     )\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[1;32m--> 649\u001b[1;33m             \u001b[0mldata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m         )\n\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[0;32m   2024\u001b[0m         raise ValueError(\n\u001b[0;32m   2025\u001b[0m             \u001b[1;34m\"columns overlap but no suffix specified: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2026\u001b[1;33m             \u001b[1;34m\"{rename}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_rename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2027\u001b[0m         )\n\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['Other'], dtype='object')"
     ]
    }
   ],
   "source": [
    "df_new = list_of_df[ (len(list_of_df)-1 )].join( list_of_df[ (len(list_of_df)-2 )] )\n",
    "\n",
    "for dframe in range(0, len(list_of_df)-2 ):\n",
    "    df_new = df_new.join( list_of_df[dframe] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#sample joining table\n",
    "\n",
    "df_new = df31.join(df29)\n",
    "df29 = df29.drop(df29.columns[[0,1]], axis=1)\n",
    "df30 = df30.drop(df30.columns[[0,1]], axis=1)\n",
    "\n",
    "df_new = df31.join(df29)\n",
    "df_new = df_new.join(df30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.dropna(how = 'any')\n",
    "\n",
    "print( df_new.head() )\n",
    "print(len(df_new.index) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Regression Machine learning using sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.a Prepping: extract the name of the column\n",
    "\n",
    "key_name =  df_new.keys()\n",
    "X_name = key_name[2:]\n",
    "\n",
    "X_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.b Select the data we want.\n",
    "### In this case, we only pick Phase 2, and the Overall Status has to be either\n",
    "\n",
    "df_filtered = df_new[ df_new[\"Phase_2\"] == 1 ]\n",
    "df_filtered = df_filtered[ (df_filtered[\"OverallStatus\"] == \"Completed\") | (df_filtered [\"OverallStatus\"] ==\"Terminated\")  ]\n",
    "\n",
    "# print(df_filtered.describe() )\n",
    "\n",
    "#drop null values\n",
    "# df_filtered = df_filtered.dropna(how = 'any')\n",
    "\n",
    "print(len(df_filtered.index ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.groupby(\"OverallStatus\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.c Assign data to X and Y\n",
    "\n",
    "X = df_filtered[X_name]\n",
    "y = df_filtered[\"OverallStatus\"]\n",
    "print(X.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.d Use train_test_split to create training and testing data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data and calculate the scores for the training and testing data\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "### END SOLUTION \n",
    "\n",
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(X_test)\n",
    "print(f\"First 30 Predictions:   {predictions[:30]}\")\n",
    "print(f\"First 30 Actual labels: {y_test[:30].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. save the regression model\n",
    "filename = \"clinical_trial.sav\"\n",
    "pickle.dump(classifier , open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. Try applying the model into other non-concluded trial.\n",
    "\n",
    "### 5.a Predict using other data\n",
    "\n",
    "df_other_trial = df_new[ df_new[\"Phase_2\"] == 1 ]\n",
    "df_other_trial = df_other_trial[ (df_other_trial[\"OverallStatus\"] != \"Completed\") & (df_other_trial[\"OverallStatus\"] != \"Terminated\") ]\n",
    "df_other_trial.tail()\n",
    "\n",
    "\n",
    "### MARKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_other_trial[\"OverallStatus\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.a (continued): Extract the NCTID of each trial to be used for visualization later\n",
    "\n",
    "other_NCTId = df_other_trial[\"NCTId\"].values\n",
    "other_NCTId\n",
    "\n",
    "### MARKED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5.b Assign data to X and Y\n",
    "\n",
    "X_other = df_other_trial[X_name]\n",
    "y_other = df_other_trial[\"OverallStatus\"]\n",
    "print(X.shape , y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Using X_other, predict the result!\n",
    "\n",
    "predictions_other = classifier.predict(X_other)\n",
    "print(f\"First 30 Predictions:   {predictions[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.c Show the result, and save it as CSV\n",
    "\n",
    "other_result = pd.DataFrame({\"Prediction\": predictions_other}).reset_index(drop=True)\n",
    "other_result[\"value_count\"] = 1\n",
    "\n",
    "other_result [\"NCTId\"] = other_NCTId\n",
    "\n",
    "### Don't forget to change the file name!\n",
    "file_name = \"log_reg_full.csv\"\n",
    "\n",
    "other_result.to_csv(file_name)\n",
    "\n",
    "other_result\n",
    "\n",
    "### MARKED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_result.groupby(\"Prediction\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid =pd.read_csv( \"covid19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
